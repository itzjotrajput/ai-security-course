# Module 3 â€” Model Integrity & Adversarial Robustness

## Objective
Understand how models can be manipulated and hardened.

---

## Red Team Focus

- Obfuscation techniques
- Confidence manipulation
- Bypass simulation

---

## Blue Team Focus

- Input normalization
- Adversarial testing
- Anomaly detection
- Model performance monitoring

---

## Exercise

Create a simple text classifier.
Test evasion.
Add normalization.
Compare results.
